{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"bengali-graphemes-starter-eda-multi-output-cnn.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"haQxrBWTWaCI","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yP6WMs3XZGg","colab_type":"code","colab":{}},"source":["%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"VKPoaSIaOjEa","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from tqdm.auto import tqdm\n","from glob import glob\n","import time, gc\n","import cv2\n","\n","from tensorflow import keras\n","import matplotlib.image as mpimg\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Model\n","from keras.models import clone_model\n","from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n","from keras.optimizers import Adam\n","from keras.callbacks import ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('../dataset/'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output.\n","\n","dataset_dir = '../dataset'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"OVUCRfZsOjEh","colab_type":"code","colab":{}},"source":["train_df_ = pd.read_csv(dataset_dir + '/train.csv')\n","test_df_ = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1nS-OYjOjEl","colab_type":"code","colab":{}},"source":["train_df_.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORK7se6iOjEp","colab_type":"code","colab":{}},"source":["test_df_.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ukag6z3eOjEs","colab_type":"code","colab":{}},"source":["sample_sub_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QveW1LJlOjEv","colab_type":"code","colab":{}},"source":["class_map_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5BXFJocOOjEz","colab_type":"code","colab":{}},"source":["print(f'Size of training data: {train_df_.shape}')\n","print(f'Size of test data: {test_df_.shape}')\n","print(f'Size of class map: {class_map_df.shape}')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IqT1bvCMOjE2","colab_type":"text"},"source":["## Exploratory Data Analysis\n","Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods."]},{"cell_type":"code","metadata":{"id":"ykpIP3A4OjE3","colab_type":"code","colab":{}},"source":["HEIGHT = 236\n","WIDTH = 236\n","\n","def get_n(df, field, n, top=True):\n","    top_graphemes = df.groupby([field]).size().reset_index(name='counts')['counts'].sort_values(ascending=not top)[:n]\n","    top_grapheme_roots = top_graphemes.index\n","    top_grapheme_counts = top_graphemes.values\n","    top_graphemes = class_map_df[class_map_df['component_type'] == field].reset_index().iloc[top_grapheme_roots]\n","    top_graphemes.drop(['component_type', 'label'], axis=1, inplace=True)\n","    top_graphemes.loc[:, 'count'] = top_grapheme_counts\n","    return top_graphemes\n","\n","def image_from_char(char):\n","    image = Image.new('RGB', (WIDTH, HEIGHT))\n","    draw = ImageDraw.Draw(image)\n","    myfont = ImageFont.truetype(dataset_dir + '/kalpurush-fonts/kalpurush-2.ttf', 120)\n","    w, h = draw.textsize(char, font=myfont)\n","    draw.text(((WIDTH - w) / 2,(HEIGHT - h) / 3), char, font=myfont)\n","\n","    return image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhVH6yDaOjE6","colab_type":"text"},"source":["### Number of unique values"]},{"cell_type":"code","metadata":{"id":"5r74S9HrOjE6","colab_type":"code","colab":{}},"source":["print(f'Number of unique grapheme roots: {train_df_[\"grapheme_root\"].nunique()}')\n","print(f'Number of unique vowel diacritic: {train_df_[\"vowel_diacritic\"].nunique()}')\n","print(f'Number of unique consonant diacritic: {train_df_[\"consonant_diacritic\"].nunique()}')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V3G_-POJOjE-","colab_type":"text"},"source":["### Most used top 10 Grapheme Roots in training set"]},{"cell_type":"code","metadata":{"id":"OdyJCi9eOjE_","colab_type":"code","colab":{}},"source":["top_10_roots = get_n(train_df_, 'grapheme_root', 10)\n","top_10_roots"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HY7_7OXvOjFB","colab_type":"code","colab":{}},"source":["f, ax = plt.subplots(2, 5, figsize=(16, 8))\n","ax = ax.flatten()\n","\n","for i in range(10):\n","    ax[i].imshow(image_from_char(top_10_roots['component'].iloc[i]), cmap='Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IkMdU3IQOjFE","colab_type":"text"},"source":["### Least used 10 Grapheme Roots in training set"]},{"cell_type":"code","metadata":{"id":"A7p0C3TVOjFF","colab_type":"code","colab":{}},"source":["bottom_10_roots = get_n(train_df_, 'grapheme_root', 10, False)\n","bottom_10_roots"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnT5cAuIOjFH","colab_type":"code","colab":{}},"source":["f, ax = plt.subplots(2, 5, figsize=(16, 8))\n","ax = ax.flatten()\n","\n","for i in range(10):\n","    ax[i].imshow(image_from_char(bottom_10_roots['component'].iloc[i]), cmap='Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AclGwvBLOjFJ","colab_type":"text"},"source":["### Top 5 Vowel Diacritic in taining data"]},{"cell_type":"code","metadata":{"id":"TwRoClfPOjFK","colab_type":"code","colab":{}},"source":["top_5_vowels = get_n(train_df_, 'vowel_diacritic', 5)\n","top_5_vowels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Hrdn8_KOjFN","colab_type":"code","colab":{}},"source":["f, ax = plt.subplots(1, 5, figsize=(16, 8))\n","ax = ax.flatten()\n","\n","for i in range(5):\n","    ax[i].imshow(image_from_char(top_5_vowels['component'].iloc[i]), cmap='Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HHmOjvXOjFQ","colab_type":"text"},"source":["### Top 5 Consonant Diacritic in training data"]},{"cell_type":"code","metadata":{"id":"b5sVwtYqOjFQ","colab_type":"code","colab":{}},"source":["top_5_consonants = get_n(train_df_, 'consonant_diacritic', 5)\n","top_5_consonants"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtwaEJ6ROjFS","colab_type":"code","colab":{}},"source":["f, ax = plt.subplots(1, 5, figsize=(16, 8))\n","ax = ax.flatten()\n","\n","for i in range(5):\n","    ax[i].imshow(image_from_char(top_5_consonants['component'].iloc[i]), cmap='Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1qRJro_OjFV","colab_type":"code","colab":{}},"source":["train_df_ = train_df_.drop(['grapheme'], axis=1, inplace=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sm3HbjtlOjFX","colab_type":"code","colab":{}},"source":["train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']] = train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].astype('uint8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6W8giKFsOjFa","colab_type":"code","colab":{}},"source":["IMG_SIZE=64\n","N_CHANNELS=1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"POpZa9gIOjFc","colab_type":"text"},"source":["Let's apply some image processing (credits: [this kernel](https://www.kaggle.com/shawon10/bangla-graphemes-image-processing-deep-cnn)) while resizing the images, which will center crop the region of interest from the original images."]},{"cell_type":"code","metadata":{"id":"EjwCnLQ3OjFd","colab_type":"code","colab":{}},"source":["def resize(df, size=64, need_progress_bar=True):\n","    resized = {}\n","    resize_size=64\n","    if need_progress_bar:\n","        for i in tqdm(range(df.shape[0])):\n","            image=df.loc[df.index[i]].values.reshape(137,236)\n","            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","\n","            idx = 0 \n","            ls_xmin = []\n","            ls_ymin = []\n","            ls_xmax = []\n","            ls_ymax = []\n","            for cnt in contours:\n","                idx += 1\n","                x,y,w,h = cv2.boundingRect(cnt)\n","                ls_xmin.append(x)\n","                ls_ymin.append(y)\n","                ls_xmax.append(x + w)\n","                ls_ymax.append(y + h)\n","            xmin = min(ls_xmin)\n","            ymin = min(ls_ymin)\n","            xmax = max(ls_xmax)\n","            ymax = max(ls_ymax)\n","\n","            roi = image[ymin:ymax,xmin:xmax]\n","            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n","            resized[df.index[i]] = resized_roi.reshape(-1)\n","    else:\n","        for i in range(df.shape[0]):\n","            #image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size),None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n","            image=df.loc[df.index[i]].values.reshape(137,236)\n","            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","\n","            idx = 0 \n","            ls_xmin = []\n","            ls_ymin = []\n","            ls_xmax = []\n","            ls_ymax = []\n","            for cnt in contours:\n","                idx += 1\n","                x,y,w,h = cv2.boundingRect(cnt)\n","                ls_xmin.append(x)\n","                ls_ymin.append(y)\n","                ls_xmax.append(x + w)\n","                ls_ymax.append(y + h)\n","            xmin = min(ls_xmin)\n","            ymin = min(ls_ymin)\n","            xmax = max(ls_xmax)\n","            ymax = max(ls_ymax)\n","\n","            roi = image[ymin:ymax,xmin:xmax]\n","            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n","            resized[df.index[i]] = resized_roi.reshape(-1)\n","    resized = pd.DataFrame(resized).T\n","    return resized"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpcNR2BNOjFf","colab_type":"code","colab":{}},"source":["def get_dummies(df):\n","    cols = []\n","    for col in df:\n","        cols.append(pd.get_dummies(df[col].astype(str)))\n","    return pd.concat(cols, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-0RWm9OOjFh","colab_type":"text"},"source":["## Basic Model"]},{"cell_type":"code","metadata":{"id":"leiShHQfOjFh","colab_type":"code","colab":{}},"source":["inputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n","\n","model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1))(inputs)\n","model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = MaxPool2D(pool_size=(2, 2))(model)\n","model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n","model = Dropout(rate=0.3)(model)\n","\n","model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = MaxPool2D(pool_size=(2, 2))(model)\n","model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = Dropout(rate=0.3)(model)\n","\n","model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = MaxPool2D(pool_size=(2, 2))(model)\n","model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = Dropout(rate=0.3)(model)\n","\n","model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = MaxPool2D(pool_size=(2, 2))(model)\n","model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n","model = BatchNormalization(momentum=0.15)(model)\n","model = Dropout(rate=0.3)(model)\n","\n","model = Flatten()(model)\n","model = Dense(1024, activation = \"relu\")(model)\n","model = Dropout(rate=0.3)(model)\n","dense = Dense(512, activation = \"relu\")(model)\n","\n","head_root = Dense(168, activation = 'softmax')(dense)\n","head_vowel = Dense(11, activation = 'softmax')(dense)\n","head_consonant = Dense(7, activation = 'softmax')(dense)\n","\n","model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEjKTJxjOjFj","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DJfRtu3KOjFm","colab_type":"text"},"source":["Let's visualize the 3-tailed (3 output) CNN by plotting it."]},{"cell_type":"code","metadata":{"id":"sjQddaDdOjFn","colab_type":"code","colab":{}},"source":["from keras.utils import plot_model\n","plot_model(model, to_file='model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yl0eKq9qOjFp","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwRzKj1vOjFr","colab_type":"code","colab":{}},"source":["# Set a learning rate annealer. Learning rate will be half after 3 epochs if accuracy is not increased\n","learning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_3_accuracy', \n","                                            patience=3, \n","                                            verbose=1,\n","                                            factor=0.5, \n","                                            min_lr=0.00001)\n","learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_4_accuracy', \n","                                            patience=3, \n","                                            verbose=1,\n","                                            factor=0.5, \n","                                            min_lr=0.00001)\n","learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_5_accuracy', \n","                                            patience=3, \n","                                            verbose=1,\n","                                            factor=0.5, \n","                                            min_lr=0.00001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIGk4Rl0OjFt","colab_type":"code","colab":{}},"source":["batch_size = 256\n","epochs = 30"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c6GXXxQcOjFv","colab_type":"code","colab":{}},"source":["class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n","\n","    def flow(self,\n","             x,\n","             y=None,\n","             batch_size=32,\n","             shuffle=True,\n","             sample_weight=None,\n","             seed=None,\n","             save_to_dir=None,\n","             save_prefix='',\n","             save_format='png',\n","             subset=None):\n","\n","        targets = None\n","        target_lengths = {}\n","        ordered_outputs = []\n","        for output, target in y.items():\n","            if targets is None:\n","                targets = target\n","            else:\n","                targets = np.concatenate((targets, target), axis=1)\n","            target_lengths[output] = target.shape[1]\n","            ordered_outputs.append(output)\n","\n","\n","        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n","                                         shuffle=shuffle):\n","            target_dict = {}\n","            i = 0\n","            for output in ordered_outputs:\n","                target_length = target_lengths[output]\n","                target_dict[output] = flowy[:, i: i + target_length]\n","                i += target_length\n","\n","            yield flowx, target_dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QW-vsnNsOjFy","colab_type":"code","colab":{}},"source":["HEIGHT = 137\n","WIDTH = 236"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZkkj7LIOjF0","colab_type":"text"},"source":["### Training loop"]},{"cell_type":"code","metadata":{"id":"eF0hHefPOjF1","colab_type":"code","colab":{}},"source":["histories = []\n","for i in range(4):\n","    train_df = pd.merge(pd.read_parquet(dataset_dir + '/train_image_data_{}.parquet'.format(i)), train_df_, on='image_id').drop(['image_id'], axis=1)\n","    \n","    # Visualize few samples of current training dataset\n","    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(16, 8))\n","    count=0\n","    for row in ax:\n","        for col in row:\n","            col.imshow(resize(train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1).iloc[[count]], need_progress_bar=False).values.reshape(-1).reshape(IMG_SIZE, IMG_SIZE).astype(np.float64))\n","            count += 1\n","    plt.show()\n","    \n","    X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n","    X_train = resize(X_train)/255\n","    \n","    # CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n","    X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","    \n","    Y_train_root = pd.get_dummies(train_df['grapheme_root']).values\n","    Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values\n","    Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values\n","\n","    print(f'Training images: {X_train.shape}')\n","    print(f'Training labels root: {Y_train_root.shape}')\n","    print(f'Training labels vowel: {Y_train_vowel.shape}')\n","    print(f'Training labels consonants: {Y_train_consonant.shape}')\n","\n","    # Divide the data into training and validation set\n","    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=666)\n","    del train_df\n","    del X_train\n","    del Y_train_root, Y_train_vowel, Y_train_consonant\n","\n","    # Data augmentation for creating more training data\n","    datagen = MultiOutputDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.15, # Randomly zoom image \n","        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=False,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","\n","    # This will just calculate parameters required to augment the given data. This won't perform any augmentations\n","    datagen.fit(x_train)\n","\n","    # Fit the model\n","    history = model.fit_generator(datagen.flow(x_train, {'dense_3': y_train_root, 'dense_4': y_train_vowel, 'dense_5': y_train_consonant}, batch_size=batch_size),\n","                              epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n","                              steps_per_epoch=x_train.shape[0] // batch_size, \n","                              callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant])\n","\n","    histories.append(history)\n","    \n","    # Delete to reduce memory usage\n","    del x_train\n","    del x_test\n","    del y_train_root\n","    del y_test_root\n","    del y_train_vowel\n","    del y_test_vowel\n","    del y_train_consonant\n","    del y_test_consonant\n","    gc.collect()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9mWL3HRUOjF3","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","def plot_loss(his, epoch, title):\n","    plt.style.use('ggplot')\n","    plt.figure()\n","    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n","    plt.plot(np.arange(0, epoch), his.history['dense_3_loss'], label='train_root_loss')\n","    plt.plot(np.arange(0, epoch), his.history['dense_4_loss'], label='train_vowel_loss')\n","    plt.plot(np.arange(0, epoch), his.history['dense_5_loss'], label='train_consonant_loss')\n","    \n","    plt.plot(np.arange(0, epoch), his.history['val_dense_3_loss'], label='val_train_root_loss')\n","    plt.plot(np.arange(0, epoch), his.history['val_dense_4_loss'], label='val_train_vowel_loss')\n","    plt.plot(np.arange(0, epoch), his.history['val_dense_5_loss'], label='val_train_consonant_loss')\n","    \n","    plt.title(title)\n","    plt.xlabel('Epoch #')\n","    plt.ylabel('Loss')\n","    plt.legend(loc='upper right')\n","    plt.show()\n","\n","def plot_acc(his, epoch, title):\n","    plt.style.use('ggplot')\n","    plt.figure()\n","    plt.plot(np.arange(0, epoch), his.history['dense_3_accuracy'], label='train_root_acc')\n","    plt.plot(np.arange(0, epoch), his.history['dense_4_accuracy'], label='train_vowel_accuracy')\n","    plt.plot(np.arange(0, epoch), his.history['dense_5_accuracy'], label='train_consonant_accuracy')\n","    \n","    plt.plot(np.arange(0, epoch), his.history['val_dense_3_accuracy'], label='val_root_acc')\n","    plt.plot(np.arange(0, epoch), his.history['val_dense_4_accuracy'], label='val_vowel_accuracy')\n","    plt.plot(np.arange(0, epoch), his.history['val_dense_5_accuracy'], label='val_consonant_accuracy')\n","    plt.title(title)\n","    plt.xlabel('Epoch #')\n","    plt.ylabel('Accuracy')\n","    plt.legend(loc='upper right')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xSKhyaBOOjF6","colab_type":"code","colab":{}},"source":["for dataset in range(4):\n","    plot_loss(histories[dataset], epochs, f'Training Dataset: {dataset}')\n","    plot_acc(histories[dataset], epochs, f'Training Dataset: {dataset}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVJiK3QxOjF8","colab_type":"code","colab":{}},"source":["del histories\n","gc.collect()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"btER5nifOjF-","colab_type":"code","colab":{}},"source":["preds_dict = {\n","    'grapheme_root': [],\n","    'vowel_diacritic': [],\n","    'consonant_diacritic': []\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJJATTevOjF_","colab_type":"code","colab":{}},"source":["components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n","target=[] # model predictions placeholder\n","row_id=[] # row_id place holder\n","for i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + '/test_image_data_{}.parquet'.format(i)) \n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test = resize(df_test_img, need_progress_bar=False)/255\n","    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","    \n","    preds = model.predict(X_test)\n","\n","    for i, p in enumerate(preds_dict):\n","        preds_dict[p] = np.argmax(preds[i], axis=1)\n","\n","    for k,id in enumerate(df_test_img.index.values):  \n","        for i,comp in enumerate(components):\n","            id_sample=id+'_'+comp\n","            row_id.append(id_sample)\n","            target.append(preds_dict[comp][k])\n","    del df_test_img\n","    del X_test\n","    gc.collect()\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","df_sample.to_csv('submission.csv',index=False)\n","df_sample.head()"],"execution_count":0,"outputs":[]}]}