{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ensemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpxptohuDISM2ngMY/cI61"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"E6zaJbq1hRVP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"f2acbca4-b945-4787-9e9d-8d87134a00c3","executionInfo":{"status":"ok","timestamp":1583757973176,"user_tz":-540,"elapsed":679,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lco1QBlvhlkc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"db1ec390-002d-4479-f63d-52f7b9e39f7e","executionInfo":{"status":"ok","timestamp":1583757975935,"user_tz":-540,"elapsed":3419,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["!pip install efficientnet_pytorch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y1QquIvhdWRJ","colab_type":"code","colab":{}},"source":["# KaggleでEfficientNetを動かす場合\n","\n","# %cd ../input/efficientnetdir/EfficientNet-PyTorch\n","# from efficientnet_pytorch import EfficientNet\n","# %cd ../..\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4FecSR0hql9","colab_type":"code","colab":{}},"source":["## 諸々の import\n","\n","import time\n","start = time.time()\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","import torchvision.models as models\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","import PIL\n","import gc\n","\n","\n","from preprocess import *\n","\n","\n","import model.CNN as CNN\n","import model.efficientnet as efficientnet\n","import model.resnet18 as resnet18\n","import model.resnet34 as resnet34\n","import model.resnet50 as resnet50\n","import model.resnet101 as resnet101\n","import model.resnet152 as resnet152"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EuX-Nfuchs0y","colab_type":"code","colab":{}},"source":["## Parameters\n","\n","# resize後のサイズ\n","HEIGHT = 64\n","WIDTH = 64\n","\n","# 画像を3次元にするかどうか（EfficientNetなどを使うときはTrue）\n","# enable_3d = True\n","# ResNetとEfficientNetしか使わないので、常にTrueを想定する\n","\n","# True なら submission.csv を生成する\n","create_submission = False\n","\n","#Kaggleで提出するときはTrueにする\n","kaggle_flag = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-OyavFCiD9b","colab_type":"code","colab":{}},"source":["if kaggle_flag:\n","    dataset_dir = '/kaggle/input/bengaliai-cv19'\n","    model_dir = '/kaggle/input/trained_models'\n","else:\n","    dataset_dir = '../dataset'\n","    model_dir = '../trained_models'\n","\n","# train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"surhOZ35j-gh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"5558ac92-ddbf-430f-b436-e0953f428277","executionInfo":{"status":"ok","timestamp":1583757977525,"user_tz":-540,"elapsed":4948,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["## アンサンブルの定義\n","\n","model1 = resnet18.model()\n","model2 = efficientnet.model()\n","\n","\n","ensemble = [\n","    {\n","        'model': model1,\n","        'file': 'resnet18.pth',\n","        'w_grapheme': 0.30,\n","        'w_vowel': 0.30,\n","        'w_consonant': 0.30\n","    },\n","    {\n","        'model': model2,\n","        'file': 'efficientnet_28epoch.pth',\n","        'w_grapheme': 0.70,\n","        'w_vowel': 0.70,\n","        'w_consonant': 0.70\n","    }\n","]\n","\n","# for M in ensemble としていないのは、ensembleに\"代入\"をしたいからです\n","# 参考：　https://ja.stackoverflow.com/q/31916\n","for i in range(len(ensemble)):\n","    device = torch.device('cpu')\n","    model = ensemble[i]['model']\n","    model.load_state_dict(torch.load(model_dir + '/' + ensemble[i]['file'], map_location=device))\n","    ensemble[i]['model'] = model\n","    print(\"model loaded from {}\".format(model_dir + '/' + ensemble[i]['file']))\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n","model loaded from ../trained_models/resnet18.pth\n","model loaded from ../trained_models/efficientnet_28epoch.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DvFakYtVrjZj","colab_type":"code","colab":{}},"source":["# テスト用のDataset, DataLoaderを作りたい\n","\n","class TestDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, X, transform=None, H=64, W=64):\n","        self.transform = transform\n","        self.X = X\n","        self.H = H \n","        self.W = W \n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","\n","        out_data = cv2.resize(self.X[idx].reshape(self.H, self.W), (224, 224), interpolation=cv2.INTER_AREA)\n","        out_data = out_data.reshape(224, 224, 1).astype(np.uint8)\n","        out_data = cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB)\n","        out_data = np.transpose(out_data, (2,0,1)) / 255.0\n","        out_data = out_data.reshape(3,224,224) \n","        \n","        out_data = torch.tensor(out_data, dtype=torch.float)\n","\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","\n","        return out_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dgpYRS5iH56","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"50d09714-c2c9-4ffa-9dd4-99282a85038e","executionInfo":{"status":"ok","timestamp":1583759391562,"user_tz":-540,"elapsed":1418947,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["## 提出ファイルの作成\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","for parq_i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","    # df_test_img = pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet') # Error Check!\n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test_resized = resize(df_test_img, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8)\n","    \n","    index = 0\n","    id_names = df_test_img.index.values\n","\n","    del df_test_img\n","    gc.collect()\n","\n","    test_dataset = TestDataset(X_test_resized, H=HEIGHT, W=WIDTH)\n","    test_loader = DataLoader(test_dataset, batch_size=32, num_workers=0)\n","\n","    del X_test_resized\n","    gc.collect()\n","\n","    for data in test_loader:\n","        data = Variable(data)\n","        data = try_gpu(data)\n","\n","        bs = len(data)\n","        root_ens, vowel_ens, consonant_ens = np.zeros((bs, 168)), np.zeros((bs, 11)), np.zeros((bs, 7))\n","        # ens = ensembleの意味を込めて\n","\n","        for M in ensemble:\n","            model = M['model']\n","            model = try_gpu(model)\n","\n","            root_o, vowel_o, consonant_o = model(data)\n","            root_ens += M['w_grapheme'] * root_o.data.cpu().numpy()\n","            vowel_ens += M['w_vowel'] * vowel_o.data.cpu().numpy()\n","            consonant_ens += M['w_consonant'] * consonant_o.data.cpu().numpy()\n","\n","        root_pred, vowel_pred, consonant_pred = np.argmax(root_ens, axis=1), np.argmax(vowel_ens, axis=1), np.argmax(consonant_ens, axis=1)\n","\n","        for i in range(bs):\n","            row_id.append(id_names[index]+'_consonant_diacritic')\n","            target.append(consonant_pred[i])\n","            row_id.append(id_names[index]+'_grapheme_root')\n","            target.append(root_pred[i])\n","            row_id.append(id_names[index]+'_vowel_diacritic')\n","            target.append(vowel_pred[i])\n","            index += 1\n","    \n","    del test_dataset\n","    del test_loader\n","    gc.collect()\n","\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","\n","if create_submission:\n","    df_sample.to_csv('submission.csv',index=False)\n","\n","df_sample.head(36)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","実行時間： 1415.2709159851074秒\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PloUqk5-nHI9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"22cb681a-af5f-416d-a0f8-65a4602790bd","executionInfo":{"status":"ok","timestamp":1583760055498,"user_tz":-540,"elapsed":981,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["elapsed_time = time.time() - start\n","print(f'実行時間： {elapsed_time}秒')"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Train_0_consonant_diacritic</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Train_0_grapheme_root</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Train_0_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Train_1_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Train_1_grapheme_root</td>\n","      <td>159</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        row_id  target\n","0  Train_0_consonant_diacritic       5\n","1        Train_0_grapheme_root      15\n","2      Train_0_vowel_diacritic       9\n","3  Train_1_consonant_diacritic       0\n","4        Train_1_grapheme_root     159"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"KcYi1LSJdJhr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}