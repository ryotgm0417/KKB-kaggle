{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vGJGsJfsggSr","colab_type":"code","outputId":"1a85c79d-02f9-45f0-a099-07a435d7c728","executionInfo":{"status":"ok","timestamp":1583908003937,"user_tz":-540,"elapsed":1628,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U67CYVMTg7tE","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNVEBroeewc4","colab_type":"code","outputId":"2fd4478e-c4a7-4b74-e612-820e0190faed","executionInfo":{"status":"ok","timestamp":1583908010759,"user_tz":-540,"elapsed":8365,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!pip install efficientnet_pytorch"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TqMWjaRU2KU4","colab_type":"code","colab":{}},"source":["## 諸々の import\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import recall_score\n","import cv2\n","# from tqdm.auto import tqdm\n","import copy\n","import datetime\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","import torchvision.models as models\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","import PIL\n","# from torchsummary import summary\n","import gc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbsZSbkg9SrB","colab_type":"code","colab":{}},"source":["## Parameters\n","\n","# resize後のサイズ\n","HEIGHT = 64\n","WIDTH = 64\n","\n","# 画像を3次元にするかどうか（EfficientNetなどを使うときはTrue）\n","enable_3d = True\n","\n","# True なら Cross Validation を実施する\n","# Kaggle に提出するデータを作るときは False にしてください\n","do_validation = False\n","\n","# True なら submission.csv を生成する\n","create_submission = False\n","\n","val_perc = 0.2  # validation set の割合（クロスバリデーション）\n","\n","#epochs number\n","epochs = 30\n","\n","#初期値として、保存した重みを使う時はこれをTrueに\n","load_flag = True\n","\n","#Kaggleで提出するときはTrueにする\n","kaggle_flag = False\n","\n","#loadするファイルへのパス\n","if kaggle_flag:\n","    model_path = '/kaggle/input/model_load/resnet18_epoch1_2020-03-09_14-58-43.pth'\n","else:\n","    model_path = '../trained_models/resnet18_epoch32_2020-03-09_17-18-32.pth'\n","\n","if kaggle_flag:\n","    dataset_dir = '/kaggle/input/bengaliai-cv19'\n","    model_dir = '/kaggle/input/trained_models'\n","else:\n","    dataset_dir = '../dataset'\n","    model_dir = '../trained_models'\n","\n","train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tvn9ZIpO-kz6","colab_type":"code","colab":{}},"source":["def save_ensemble(ensemble,dir):\n","    import pickle\n","    with open(dir+'/ensemble.pickle', 'wb') as f:\n","        pickle.dump(ensemble, f)\n","\n","def load_ensemble(dir):\n","    import pickle\n","    with open(dir+'/ensemble.pickle', 'rb') as f:\n","        ensemble = pickle.load(f)\n","    return ensemble"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RU66nFHqgj7K","colab_type":"code","outputId":"ee08e3bc-94d5-4059-e05a-3851c92cdcb0","executionInfo":{"status":"ok","timestamp":1583908025340,"user_tz":-540,"elapsed":22886,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#モデルの設定\n","\n","from preprocess import *\n","from save_load import *\n","import model.CNN as CNN\n","import model.efficientnet as efficientnet\n","import model.resnet18 as resnet18\n","import model.resnet34 as resnet34\n","import model.resnet50 as resnet50\n","import model.resnet101 as resnet101\n","import model.resnet152 as resnet152\n","\n","#今までに作ったensembleを使う場合\n","ensemble = load_ensemble(model_dir)\n","\n","#追加するmodelの定義\n","model1 = resnet34.model()\n","optim1 = optim.Adam(model1.parameters())\n","model2 = efficientnet.model()\n","\n","#今までの分に加えて新しいものも定義\n","name_list = [\"resnet18\",\"efficientnet81\",\"resnet34\",\"efficientnet64\"]\n","\n","add_ensemble = [\n","    {\n","        'model': model1,\n","        'file': 'resnet34_50epoch.pth'\n","    },\n","    {\n","        'model': model2,\n","        'file': 'efficientnet_64epoch.pth'\n","    }\n","]\n","\n","start = len(ensemble)\n","N_add = len(add_ensemble)\n","\n","#modelの重みのload(古いsave()で保存している場合はload_weight(model,model_path)を、新しいsave()で保存している場合はload_model(model,optim,model_path)))を\n","model1= load_weight(model1,model_dir+'/'+add_ensemble[0][\"file\"])\n","model1 = try_gpu(model1)\n","add_ensemble[0][\"model\"]= model1\n","model2= load_weight(model2,model_dir+'/'+add_ensemble[1][\"file\"])\n","model2 = try_gpu(model2)\n","add_ensemble[1][\"model\"] = model2\n","\n","\n","for i in range(len(add_ensemble)):\n","    ensemble.append(add_ensemble[i])\n","\n","del add_ensemble\n","\n","# for M in ensemble としていないのは、ensembleに\"代入\"をしたいからです\n","# 参考：　https://ja.stackoverflow.com/q/31916\n","for i in range(len(ensemble)):\n","    ensemble[i][\"name\"] = name_list[i]\n","    "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n","loaded from ../trained_models/resnet34_50epoch.pth\n","loaded from ../trained_models/efficientnet_64epoch.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h7G-i0XLtsbY","colab_type":"code","colab":{}},"source":["## train関数、test関数\n","\n","def train(model, epoch, train_loader):\n","    model.train()\n","    \n","    size = len(train_loader.dataset)\n","    pred_r, pred_v, pred_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    true_r, true_v, true_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    index = 0\n","\n","    for data in train_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        loss1 = criterion1(root_o, root_l)\n","        loss2 = criterion1(vowel_o, vowel_l)\n","        loss3 = criterion1(consonant_o, consonant_l)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","        for i in range(inputs.size(0)):\n","            pred_r[index] = root_pred[i]\n","            pred_v[index] = vowel_pred[i]\n","            pred_c[index] = consonant_pred[i]\n","            true_r[index] = root_l[i]\n","            true_v[index] = vowel_l[i]\n","            true_c[index] = consonant_l[i]\n","            index += 1\n","    recall_r = recall_score(true_r, pred_r, average='macro')\n","    recall_v = recall_score(true_v, pred_v, average='macro')\n","    recall_c = recall_score(true_c, pred_c, average='macro')\n","    final_score = (2.*recall_r + recall_v + recall_c) / 4.\n","\n","    print(f'Root Recall(train): {recall_r:.5f}')\n","    print(f'Vowel Recall(train): {recall_v:.5f}')\n","    print(f'Consonant Recall(train): {recall_c:.5f}')\n","    print(f'Score(train): {final_score:.5f}')\n","   \n","\n","def test(model, test_loader):\n","    model.eval()\n","    print(\"test start\")\n","    size = len(test_loader.dataset)\n","    pred_r, pred_v, pred_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    true_r, true_v, true_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    index = 0\n","    \n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        \n","        root_o, vowel_o, consonant_o = model(inputs) \n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        for i in range(inputs.size(0)):\n","            pred_r[index] = root_pred[i]\n","            pred_v[index] = vowel_pred[i]\n","            pred_c[index] = consonant_pred[i]\n","            true_r[index] = root_l[i]\n","            true_v[index] = vowel_l[i]\n","            true_c[index] = consonant_l[i]\n","            index += 1\n","\n","    recall_r = recall_score(true_r, pred_r, average='macro')\n","    recall_v = recall_score(true_v, pred_v, average='macro')\n","    recall_c = recall_score(true_c, pred_c, average='macro')\n","    final_score = (2.*recall_r + recall_v + recall_c) / 4.\n","\n","    print(f'Root Recall(test): {recall_r:.5f}')\n","    print(f'Vowel Recall(test): {recall_v:.5f}')\n","    print(f'Consonant Recall(test): {recall_c:.5f}')\n","    print(f'Score(test): {final_score:.5f}')\n","    return true_r,pred_r,true_v,pred_v,true_c,pred_c\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wZ0lQFJ3Ajz","colab_type":"code","outputId":"061a57af-7a71-47d4-f290-c7d716550a4e","executionInfo":{"status":"ok","timestamp":1583908413227,"user_tz":-540,"elapsed":410693,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":244}},"source":["## データの読み込み\n","\n","X_all = np.empty((0, HEIGHT*WIDTH))\n","Y_root_all = np.empty((0, 168))\n","Y_vowel_all = np.empty((0, 11))\n","Y_cons_all = np.empty((0, 7))\n","\n","for parq_i in range(4):\n","    print(f'Parquet {parq_i} を読み込み中')\n","    train_df_with_img = pd.merge(pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)\n","    \n","    X = train_df_with_img.drop(columns=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'])\n","    X_resized = resize(X, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8) # astype(np.uint8)をしてあげることで後で cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB) が実行できるようになる\n","    \n","    Y_root = pd.get_dummies(train_df_with_img['grapheme_root']).values\n","    Y_vowel = pd.get_dummies(train_df_with_img['vowel_diacritic']).values\n","    Y_cons = pd.get_dummies(train_df_with_img['consonant_diacritic']).values\n","\n","    X_all = np.append(X_all, X_resized, axis=0)\n","    Y_root_all = np.append(Y_root_all, Y_root, axis=0)\n","    Y_vowel_all = np.append(Y_vowel_all, Y_vowel, axis=0)\n","    Y_cons_all = np.append(Y_cons_all, Y_cons, axis=0)\n","\n","    del X\n","    del X_resized\n","    del Y_root\n","    del Y_vowel \n","    del Y_cons \n","    gc.collect()\n","\n","print(X_all.shape)\n","print(Y_root_all.shape)\n","print(Y_vowel_all.shape)\n","print(Y_cons_all.shape)\n","\n","Y_all = [Y_root_all, Y_vowel_all, Y_cons_all]\n","\n","trainval_dataset = MyDataset(X_all, Y_all, enable_3d=enable_3d, H=HEIGHT, W=WIDTH)\n","\n","del X_all\n","del Y_root_all\n","del Y_vowel_all\n","del Y_cons_all\n","del Y_all\n","gc.collect()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Parquet 0 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","Parquet 1 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","Parquet 2 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","Parquet 3 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","(200840, 4096)\n","(200840, 168)\n","(200840, 11)\n","(200840, 7)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"ee2x8byvB8eW","colab_type":"code","outputId":"92c24929-eb7a-4048-ce60-05f947ca73f6","executionInfo":{"status":"ok","timestamp":1583908413232,"user_tz":-540,"elapsed":410679,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## data_loaderの作成\n","\n","if do_validation:\n","    n_samples = len(trainval_dataset)\n","    train_size = int(len(trainval_dataset)*(1.0 - val_perc))\n","    val_size = n_samples - train_size\n","    print(f'train size: {train_size}, validation size: {val_size}')\n","\n","    subset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n","\n","    if enable_3d:\n","        train_dataset = TransformDataset(subset, transform=transforms.RandomChoice(\n","            [transform_none, transform_crop224, transform_rotate, transform_noise]\n","        ))\n","\n","    else:\n","        train_dataset = TransformDataset(subset, transform=transforms.RandomChoice(\n","            [transform_none, transform_crop64, transform_rotate, transform_noise]\n","        ))\n","\n","    del trainval_dataset\n","    del subset\n","    gc.collect()\n","\n","    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False, num_workers=4)\n","    val_loader = DataLoader(dataset=val_dataset, batch_size=32, num_workers=0)\n","\n","    # メモリ節約\n","    del train_dataset\n","    del val_dataset\n","    gc.collect()\n","\n","else:\n","    n_samples = len(trainval_dataset)\n","    print(f'train size: {n_samples}')\n","\n","    if enable_3d:\n","        trainval_dataset.transform = transforms.RandomChoice(\n","            [transform_none, transform_crop224, transform_rotate, transform_noise]\n","        )\n","    \n","    else:\n","        trainval_dataset.transform = transforms.RandomChoice(\n","            [transform_none, transform_crop64, transform_rotate, transform_noise]\n","        )\n","\n","    train_loader = DataLoader(dataset=trainval_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","    # メモリ節約\n","    del trainval_dataset\n","    gc.collect()\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["train size: 200840\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"clFpsmVBpr_h","colab_type":"code","colab":{}},"source":["def model_compare(ensemble,data_loader,start):\n","    for i in range(len(ensemble)-start):\n","        true_r,pred_r,true_v,pred_v,true_c,pred_c = test(ensemble[i+start][\"model\"],data_loader)\n","        ensemble[i+start][\"correct_r\"] = true_r==pred_r\n","        ensemble[i+start][\"correct_v\"] = true_v==pred_v\n","        ensemble[i+start][\"correct_c\"] = true_c==pred_c\n","    return ensemble\n","\n","def make_df(ensemble):\n","    N = len(ensemble)\n","    #dfの作成\n","    df = pd.DataFrame()\n","    for i in range(N):\n","        df[ensemble[i][\"name\"]+\"_r\"]=ensemble[i][\"correct_r\"]\n","        df[ensemble[i][\"name\"]+\"_v\"]=ensemble[i][\"correct_v\"]\n","        df[ensemble[i][\"name\"]+\"_c\"]=ensemble[i][\"correct_c\"]\n","    return df\n","\n","def make_table(df,dir):\n","    N = len(ensemble)\n","    for i in range(N-1):\n","        for j in range(i+1,N):\n","            df1 = pd.crosstab(df[ensemble[i][\"name\"]+\"_r\"],df[ensemble[j][\"name\"]+\"_r\"],margins=True)\n","            df2 = pd.crosstab(df[ensemble[i][\"name\"]+\"_v\"],df[ensemble[j][\"name\"]+\"_v\"],margins=True)\n","            df3 = pd.crosstab(df[ensemble[i][\"name\"]+\"_c\"],df[ensemble[j][\"name\"]+\"_c\"],margins=True)\n","            print(df1)\n","            print()\n","            print(df2)\n","            print()\n","            print(df3)\n","            #dfの保存\n","            df1.to_csv(dir+'/'+ensemble[i][\"name\"]+\"-\"+ensemble[j][\"name\"]+\"_r.csv\")\n","            df2.to_csv(dir+'/'+ensemble[i][\"name\"]+\"-\"+ensemble[j][\"name\"]+\"_v.csv\")\n","            df3.to_csv(dir+'/'+ensemble[i][\"name\"]+\"-\"+ensemble[j][\"name\"]+\"_c.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWN2hnO2rwyd","colab_type":"code","outputId":"1083641b-85f0-48c4-d53b-12bd6ade43e4","executionInfo":{"status":"ok","timestamp":1583909174720,"user_tz":-540,"elapsed":1172143,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":157}},"source":["ensemble = model_compare(ensemble,train_loader,start)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Root Recall(test): 0.98840\n","Vowel Recall(test): 0.99594\n","Consonant Recall(test): 0.99462\n","Score(test): 0.99184\n","Root Recall(test): 0.99871\n","Vowel Recall(test): 0.99879\n","Consonant Recall(test): 0.99833\n","Score(test): 0.99863\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nrv43Zy6xfJE","colab_type":"code","outputId":"d3a01c23-ff40-477d-fd4d-ee028c321b99","executionInfo":{"status":"ok","timestamp":1583909176831,"user_tz":-540,"elapsed":1174245,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df = make_df(ensemble)\n","make_table(df,model_dir)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["efficientnet81_r  False    True     All\n","resnet18_r                             \n","False                11    1872    1883\n","True                133  198824  198957\n","All                 144  200696  200840\n","\n","efficientnet81_v  False    True     All\n","resnet18_v                             \n","False                 2     994     996\n","True                221  199623  199844\n","All                 223  200617  200840\n","\n","efficientnet81_c  False    True     All\n","resnet18_c                             \n","False                 8     701     709\n","True                 92  200039  200131\n","All                 100  200740  200840\n","resnet34_r  False    True     All\n","resnet18_r                       \n","False         108    1775    1883\n","True         1850  197107  198957\n","All          1958  198882  200840\n","\n","resnet34_v  False    True     All\n","resnet18_v                       \n","False          37     959     996\n","True          678  199166  199844\n","All           715  200125  200840\n","\n","resnet34_c  False    True     All\n","resnet18_c                       \n","False          33     676     709\n","True          477  199654  200131\n","All           510  200330  200840\n","efficientnet64_r  False    True     All\n","resnet18_r                             \n","False                15    1868    1883\n","True                214  198743  198957\n","All                 229  200611  200840\n","\n","efficientnet64_v  False    True     All\n","resnet18_v                             \n","False                11     985     996\n","True                248  199596  199844\n","All                 259  200581  200840\n","\n","efficientnet64_c  False    True     All\n","resnet18_c                             \n","False                10     699     709\n","True                145  199986  200131\n","All                 155  200685  200840\n","resnet34_r        False    True     All\n","efficientnet81_r                       \n","False                15     129     144\n","True               1943  198753  200696\n","All                1958  198882  200840\n","\n","resnet34_v        False    True     All\n","efficientnet81_v                       \n","False                 5     218     223\n","True                710  199907  200617\n","All                 715  200125  200840\n","\n","resnet34_c        False    True     All\n","efficientnet81_c                       \n","False                 8      92     100\n","True                502  200238  200740\n","All                 510  200330  200840\n","efficientnet64_r  False    True     All\n","efficientnet81_r                       \n","False                10     134     144\n","True                219  200477  200696\n","All                 229  200611  200840\n","\n","efficientnet64_v  False    True     All\n","efficientnet81_v                       \n","False                 6     217     223\n","True                253  200364  200617\n","All                 259  200581  200840\n","\n","efficientnet64_c  False    True     All\n","efficientnet81_c                       \n","False                 5      95     100\n","True                150  200590  200740\n","All                 155  200685  200840\n","efficientnet64_r  False    True     All\n","resnet34_r                             \n","False                27    1931    1958\n","True                202  198680  198882\n","All                 229  200611  200840\n","\n","efficientnet64_v  False    True     All\n","resnet34_v                             \n","False                11     704     715\n","True                248  199877  200125\n","All                 259  200581  200840\n","\n","efficientnet64_c  False    True     All\n","resnet34_c                             \n","False                10     500     510\n","True                145  200185  200330\n","All                 155  200685  200840\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TPJjkftV_NnY","colab_type":"code","colab":{}},"source":["save_ensemble(ensemble,model_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wMIW8MM2_yfF","colab":{"base_uri":"https://localhost:8080/","height":257},"outputId":"d18da7c1-6b49-40ce-eab7-d9449841b8de","executionInfo":{"status":"error","timestamp":1583909181803,"user_tz":-540,"elapsed":1179202,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}}},"source":["## 提出ファイルの作成\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","for parq_i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","    # df_test_img = pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet') # Error Check!\n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test_resized = resize(df_test_img, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8)\n","\n","    for k, id in enumerate(df_test_img.index.values):\n","        X = X_test_resized[k]\n","\n","        if enable_3d:\n","            X = cv2.resize(X.reshape(HEIGHT, WIDTH), (224, 224),interpolation=cv2.INTER_AREA)\n","            X = X.reshape(224, 224, 1)\n","            X = cv2.cvtColor(X, cv2.COLOR_GRAY2RGB)\n","            X = np.transpose(X, (2,0,1)) / 255.0\n","            X = X.reshape(1, 3, 224, 224) \n","        \n","        else:\n","            X = X.reshape(1, 1, HEIGHT, WIDTH) / 255.0\n","\n","        test_input = torch.tensor(X, dtype=torch.float)\n","        test_input = Variable(test_input)\n","        test_input = try_gpu(test_input)\n","        \n","        model.eval()\n","        root_o, vowel_o, consonant_o = model(test_input)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        if torch.cuda.is_available():\n","            root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","\n","        root_pred, vowel_pred, consonant_pred = root_pred.item(), vowel_pred.item(), consonant_pred.item()\n","        \n","        row_id.append(id+'_consonant_diacritic')\n","        target.append(consonant_pred)\n","        row_id.append(id+'_grapheme_root')\n","        target.append(root_pred)\n","        row_id.append(id+'_vowel_diacritic')\n","        target.append(vowel_pred)\n","    \n","    del df_test_img\n","    del X_test_resized\n","    gc.collect()\n","\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","\n","if create_submission:\n","    df_sample.to_csv('submission.csv',index=False)\n","\n","df_sample.head(36)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Resizing raw image... / 前処理実行中…\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-806cca47065d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mroot_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsonant_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mroot_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowel_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsonant_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsonant_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]}]}